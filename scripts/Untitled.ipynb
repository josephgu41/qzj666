{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10eeff1d-6ddc-492e-a76c-44372ee3e589",
   "metadata": {
    "tags": []
   },
   "source": [
    "# tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d49eb-4f85-4354-9758-b65ff14dc442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49462513-3c5c-4c94-91ed-fdfc31f0e10a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# tdtsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "id": "52e94ce4",
   "metadata": {},
=======
   "id": "4e8a683d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
>>>>>>> 6c0efe485ffc2936ddb64852ed6f783299502c6e
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "WARNING: OMP_NUM_THREADS set to 12, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.\n",
      "PLEASE USE OMP_NUM_THREADS WISELY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cls_batch_num=30, cls_image_shape='3, 48, 192', cls_model_dir='/root/.paddleocr/2.0/cls', cls_thresh=0.9, det=True, det_algorithm='DB', det_db_box_thresh=0.5, det_db_thresh=0.3, det_db_unclip_ratio=2.0, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='/root/.paddleocr/2.0/det', drop_score=0.5, enable_mkldnn=False, gpu_mem=8000, image_dir='', ir_optim=True, label_list=['0', '180'], lang='ch', max_text_length=25, rec=True, rec_algorithm='CRNN', rec_batch_num=30, rec_char_dict_path='./ppocr/utils/ppocr_keys_v1.txt', rec_char_type='ch', rec_image_shape='3, 32, 320', rec_model_dir='/root/.paddleocr/2.0/rec/ch', use_angle_cls=True, use_gpu=True, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_zero_copy_run=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0309 14:37:39.826071   892 analysis_predictor.cc:1736] Deprecated. Please use CreatePredictor instead.\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  pixel_mean\n",
      "  pixel_std\n",
      "  proposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x 484 y 0 w 199 h 2\n",
      "x 415 y 0 w 66 h 1\n",
      "x 139 y 0 w 236 h 53\n",
      "x 3 y 0 w 133 h 51\n",
      "x 378 y 3 w 103 h 51\n",
      "x 484 y 4 w 199 h 51\n",
      "x 0 y 54 w 136 h 104\n",
      "x 207 y 55 w 63 h 104\n",
      "x 138 y 55 w 67 h 104\n",
      "x 273 y 56 w 410 h 52\n",
      "x 273 y 109 w 101 h 51\n",
      "x 483 y 110 w 98 h 51\n",
      "x 377 y 110 w 103 h 50\n",
      "x 584 y 111 w 99 h 51\n",
      "x 0 y 161 w 135 h 50\n",
      "x 207 y 162 w 62 h 50\n",
      "x 138 y 162 w 66 h 50\n",
      "x 272 y 163 w 411 h 52\n",
      "x 46 y 214 w 88 h 50\n",
      "x 0 y 214 w 43 h 156\n",
      "x 206 y 215 w 63 h 50\n",
      "x 137 y 215 w 66 h 50\n",
      "x 376 y 216 w 103 h 51\n",
      "x 272 y 216 w 101 h 50\n",
      "x 482 y 217 w 98 h 50\n",
      "x 584 y 218 w 99 h 50\n",
      "x 46 y 267 w 88 h 51\n",
      "x 206 y 268 w 62 h 51\n",
      "x 137 y 268 w 65 h 50\n",
      "x 271 y 269 w 102 h 50\n",
      "x 482 y 270 w 98 h 51\n",
      "x 376 y 270 w 103 h 50\n",
      "x 583 y 271 w 100 h 50\n",
      "x 45 y 320 w 88 h 51\n",
      "x 136 y 321 w 66 h 50\n",
      "x 271 y 322 w 101 h 50\n",
      "x 205 y 322 w 63 h 50\n",
      "x 482 y 323 w 97 h 51\n",
      "x 375 y 323 w 103 h 50\n",
      "x 583 y 324 w 100 h 50\n",
      "x 0 y 373 w 42 h 104\n",
      "x 136 y 374 w 65 h 50\n",
      "x 45 y 374 w 88 h 50\n",
      "x 270 y 375 w 102 h 50\n",
      "x 205 y 375 w 62 h 50\n",
      "x 375 y 376 w 103 h 50\n",
      "x 582 y 377 w 101 h 51\n",
      "x 481 y 377 w 98 h 50\n",
      "x 135 y 427 w 66 h 51\n",
      "x 44 y 427 w 88 h 50\n",
      "x 270 y 428 w 101 h 51\n",
      "x 204 y 428 w 63 h 50\n",
      "x 375 y 429 w 102 h 50\n",
      "x 582 y 430 w 101 h 51\n",
      "x 481 y 430 w 98 h 50\n",
      "x 44 y 480 w 88 h 50\n",
      "x 0 y 480 w 41 h 156\n",
      "x 204 y 481 w 62 h 50\n",
      "x 135 y 481 w 66 h 50\n",
      "x 374 y 482 w 103 h 50\n",
      "x 269 y 482 w 102 h 50\n",
      "x 480 y 483 w 98 h 50\n",
      "x 581 y 484 w 102 h 50\n",
      "x 43 y 533 w 88 h 50\n",
      "x 269 y 534 w 101 h 51\n",
      "x 203 y 534 w 63 h 50\n",
      "x 134 y 534 w 66 h 50\n",
      "x 374 y 535 w 103 h 51\n",
      "x 480 y 536 w 98 h 50\n",
      "x 581 y 537 w 102 h 50\n",
      "x 43 y 586 w 88 h 50\n",
      "x 203 y 587 w 62 h 50\n",
      "x 134 y 587 w 66 h 50\n",
      "x 373 y 588 w 103 h 51\n",
      "x 268 y 588 w 102 h 50\n",
      "x 479 y 589 w 98 h 50\n",
      "x 581 y 590 w 101 h 50\n",
      "x 0 y 639 w 130 h 50\n",
      "x 202 y 640 w 63 h 50\n",
      "x 133 y 640 w 66 h 50\n",
      "x 373 y 641 w 103 h 51\n",
      "x 268 y 641 w 102 h 50\n",
      "x 479 y 642 w 98 h 50\n",
      "x 580 y 643 w 102 h 50\n",
      "x 0 y 692 w 130 h 33\n",
      "x 133 y 693 w 549 h 32\n",
      "len 6\n",
      "len 4\n",
      "len 4\n",
      "len 4\n",
      "len 8\n",
      "len 7\n",
      "len 7\n",
      "len 8\n",
      "len 7\n",
      "len 8\n",
      "len 7\n",
      "len 7\n",
      "len 7\n",
      "len 2\n",
      "xml/微信截图_20220816142641.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:48,327 predict_system.py:88] dt_boxes num : 1, elapse : 0.7978534698486328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:48] root INFO: dt_boxes num : 1, elapse : 0.7978534698486328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:48,504 predict_system.py:103] cls num  : 1, elapse : 0.17425799369812012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:48] root INFO: cls num  : 1, elapse : 0.17425799369812012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:48,514 predict_system.py:107] rec_res num  : 1, elapse : 0.008703470230102539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:48] root INFO: rec_res num  : 1, elapse : 0.008703470230102539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:48,652 predict_system.py:88] dt_boxes num : 1, elapse : 0.06529879570007324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:48] root INFO: dt_boxes num : 1, elapse : 0.06529879570007324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:48,657 predict_system.py:103] cls num  : 1, elapse : 0.003210306167602539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:48] root INFO: cls num  : 1, elapse : 0.003210306167602539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:48,664 predict_system.py:107] rec_res num  : 1, elapse : 0.0059967041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:48] root INFO: rec_res num  : 1, elapse : 0.0059967041015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:49,258 predict_system.py:88] dt_boxes num : 0, elapse : 0.20964813232421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:49] root INFO: dt_boxes num : 0, elapse : 0.20964813232421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:49,260 predict_system.py:103] cls num  : 0, elapse : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:49] root INFO: cls num  : 0, elapse : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:49,261 predict_system.py:107] rec_res num  : 0, elapse : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:49] root INFO: rec_res num  : 0, elapse : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:49,318 predict_system.py:88] dt_boxes num : 1, elapse : 0.020315170288085938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:49] root INFO: dt_boxes num : 1, elapse : 0.020315170288085938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:49,323 predict_system.py:103] cls num  : 1, elapse : 0.0033664703369140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:49] root INFO: cls num  : 1, elapse : 0.0033664703369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2023-03-09 14:37:49,330 predict_system.py:107] rec_res num  : 1, elapse : 0.0048618316650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/03/09 14:37:49] root INFO: rec_res num  : 1, elapse : 0.0048618316650390625\n"
=======
      "W0309 13:47:03.706722   108 init.cc:179] Compiled with WITH_GPU, but no GPU found in runtime.\n",
      "/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/framework.py:516: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\n",
      "  warnings.warn(\n"
>>>>>>> 6c0efe485ffc2936ddb64852ed6f783299502c6e
     ]
    },
    {
     "ename": "RuntimeError",
<<<<<<< HEAD
     "evalue": "ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 91.741699MB memory on GPU 0, 10.692383GB memory has been allocated and available memory is only 62.500000MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n",
=======
     "evalue": "No CUDA GPUs are available",
>>>>>>> 6c0efe485ffc2936ddb64852ed6f783299502c6e
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
<<<<<<< HEAD
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mprint\u001b[39m(td_xml_output \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m])\n\u001b[1;32m     76\u001b[0m output_to_xml(boxes, td_xml_output \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m])\n\u001b[0;32m---> 77\u001b[0m tocr\u001b[39m.\u001b[39;49moutput_to_csv(boxes, table_processed)\n",
      "File \u001b[0;32m~/autodl-tmp/Multi-Type-TD-TSR/scripts/table_ocr.py:54\u001b[0m, in \u001b[0;36moutput_to_csv\u001b[0;34m(finalboxes, img)\u001b[0m\n\u001b[1;32m     49\u001b[0m out\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m(erosion\u001b[39m.\u001b[39msum() \u001b[39m!=\u001b[39m erosion\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39merosion\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m):\n\u001b[1;32m     51\u001b[0m     \n\u001b[1;32m     52\u001b[0m     \u001b[39m# cv2.imwrite(f\"temp_img/{abc}.png\",erosion)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[39m# abc=abc+1\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     result \u001b[39m=\u001b[39m ocr\u001b[39m.\u001b[39;49mocr(erosion, \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     56\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result:\n\u001b[1;32m     57\u001b[0m         out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m res[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/paddleocr/paddleocr.py:300\u001b[0m, in \u001b[0;36mPaddleOCR.ocr\u001b[0;34m(self, img, det, rec, cls)\u001b[0m\n\u001b[1;32m    298\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_GRAY2BGR)\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m det \u001b[39mand\u001b[39;00m rec:\n\u001b[0;32m--> 300\u001b[0m     dt_boxes, rec_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(img)\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m [[box\u001b[39m.\u001b[39mtolist(), res] \u001b[39mfor\u001b[39;00m box, res \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dt_boxes, rec_res)]\n\u001b[1;32m    302\u001b[0m \u001b[39melif\u001b[39;00m det \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rec:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/paddleocr/tools/infer/predict_system.py:87\u001b[0m, in \u001b[0;36mTextSystem.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     86\u001b[0m     ori_im \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 87\u001b[0m     dt_boxes, elapse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext_detector(img)\n\u001b[1;32m     88\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdt_boxes num : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, elapse : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     89\u001b[0m         \u001b[39mlen\u001b[39m(dt_boxes), elapse))\n\u001b[1;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m dt_boxes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/paddleocr/tools/infer/predict_det.py:165\u001b[0m, in \u001b[0;36mTextDetector.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     im \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39mfluid\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mPaddleTensor(img)\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49mrun([im])\n\u001b[1;32m    166\u001b[0m outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m output_tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_tensors:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 91.741699MB memory on GPU 0, 10.692383GB memory has been allocated and available memory is only 62.500000MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \nIf the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n"
=======
      "Cell \u001b[0;32mIn[1], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#set model weights\u001b[39;00m\n\u001b[1;32m     96\u001b[0m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mWEIGHTS \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;66;03m# Set path model .pth\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    100\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(folder)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/detectron2/engine/defaults.py:285\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mclone()  \u001b[38;5;66;03m# cfg can be modified by model\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/detectron2/modeling/meta_arch/build.py:23\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m meta_arch \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mMETA_ARCHITECTURE\n\u001b[1;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m META_ARCH_REGISTRY\u001b[38;5;241m.\u001b[39mget(meta_arch)(cfg)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m _log_api_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodeling.meta_arch.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m meta_arch)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:612\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:359\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    363\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    364\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:359\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    363\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    364\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:381\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 381\u001b[0m         param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:610\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:172\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    176\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
>>>>>>> 6c0efe485ffc2936ddb64852ed6f783299502c6e
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from TSR import table_structure_recognition_all as tsra\n",
    "from TSR import table_structure_recognition_lines as tsrl\n",
    "from TSR import table_structure_recognition_lines_wol as tsrlwol\n",
    "from TSR import table_structure_recognition_wol as tsrwol\n",
    "import table_detection\n",
    "import table_ocr as tocr\n",
    "\n",
    "from table_xml import output_to_xml\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    type_dict = {\"borderd\":tsrl, \"unbordered\":tsrwol, \"partially\":tsrlwol, \"partially_color_inv\":tsra}\n",
    "    \n",
    "    folder='img/'\n",
    "    tsr_img_output = \"out/ts\"\n",
    "    td_img_output= \"out/td\"\n",
    "    td_xml_output=\"xml\"\n",
    "    yaml=\"/root/autodl-tmp/Multi-Type-TD-TSR/All_X152.yaml\"\n",
    "    weights=\"/root/autodl-tmp/Multi-Type-TD-TSR/model_final.pth\"\n",
    "\n",
    "    #create detectron config\n",
    "    # cfg = get_cfg(config)\n",
    "    cfg = get_cfg()\n",
    "\n",
    "    #set yaml\n",
    "    cfg.merge_from_file(yaml)\n",
    "\n",
    "    #set model weights\n",
    "    cfg.MODEL.WEIGHTS = weights # Set path model .pth\n",
    "\n",
    "    predictor = DefaultPredictor(cfg) \n",
    "\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    for file in files:\n",
    "        img = cv2.imread(folder + \"/\" + file)\n",
    "        # deskewed_image = deskewImage(img)\n",
    "        deskewed_image = img\n",
    "        table_list, table_coords = table_detection.make_prediction(deskewed_image, predictor)\n",
    "        list_table_boxes = []\n",
    "\n",
    "        for table in table_list:\n",
    "            boxes, table_processed = type_dict[\"borderd\"].recognize_structure(table)\n",
    "            list_table_boxes.append(boxes)\n",
    "            \n",
    "            if tsr_img_output:\n",
    "                cv2.imwrite(tsr_img_output + \"/\" + file, table_processed)\n",
    "            if td_img_output:\n",
    "                cv2.imwrite(td_img_output + \"/\" + file, table)\n",
    "            if td_xml_output:\n",
    "                print(td_xml_output + \"/\" + file[:-3])\n",
    "                output_to_xml(boxes, td_xml_output + \"/\" + file[:-3])\n",
    "                tocr.output_to_csv(boxes, table_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae504dae-d694-4e43-8d9c-18959a4b79ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "d1a848b0-7ad4-4e26-ae9b-32c9a1348e09",
   "metadata": {
    "tags": []
   },
=======
   "id": "cda09822",
   "metadata": {},
>>>>>>> 6c0efe485ffc2936ddb64852ed6f783299502c6e
   "source": [
    "# 图像校正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa19cc0-5c18-42c1-a3c7-df03eedf0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from TSR import table_structure_recognition_all as tsra\n",
    "from TSR import table_structure_recognition_lines as tsrl\n",
    "from TSR import table_structure_recognition_lines_wol as tsrlwol\n",
    "from TSR import table_structure_recognition_wol as tsrwol\n",
    "import table_detection\n",
    "#import table_ocr as tocr\n",
    "\n",
    "from table_xml import output_to_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a41c74c1-d54d-4402-9e1c-14eec7ac3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cfa5cf5-aa01-40b4-b80d-31f3b6944a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[26, 12, 134, 51]], [], [[163, 14, 236, 52]], [], [], [[402, 17, 102, 50]], [[507, 18, 203, 52]], [[713, 20, 7, 50]]], [[[25, 65, 134, 105]], [], [[161, 67, 66, 103]], [[229, 67, 65, 104]], [], [[297, 68, 412, 55]], [], [[712, 73, 8, 50]]], [[], [], [], [], [[296, 121, 102, 51]], [[401, 123, 102, 51]], [[506, 124, 98, 51]], [[607, 125, 101, 51], [710, 126, 10, 104]]], [[[24, 172, 133, 51]], [], [[160, 173, 66, 51]], [[228, 174, 64, 50]], [], [[295, 175, 413, 55]], [], []], [[[21, 225, 45, 156]], [[69, 225, 87, 51]], [[159, 226, 66, 51]], [[228, 227, 63, 50]], [[294, 228, 102, 51]], [[399, 229, 102, 51]], [[504, 231, 99, 50]], [[606, 232, 101, 51]]], [[], [[68, 278, 88, 51]], [[158, 279, 66, 51]], [[227, 280, 63, 51]], [[293, 281, 102, 51]], [[398, 282, 102, 51]], [[503, 284, 99, 51]], [[605, 285, 101, 51]]], [[], [[67, 332, 88, 50]], [[158, 332, 65, 51]], [[226, 333, 64, 51]], [[292, 334, 103, 51]], [[397, 335, 103, 51]], [[503, 337, 98, 51]], [[604, 338, 101, 51]]], [[[20, 384, 44, 103]], [[66, 385, 88, 50]], [[157, 386, 65, 50]], [[225, 386, 64, 51]], [[292, 387, 102, 51]], [[397, 388, 102, 51]], [[502, 390, 99, 51]], [[603, 391, 102, 51]]], [[], [[66, 438, 87, 50]], [[156, 439, 65, 50]], [[224, 439, 64, 51]], [[291, 440, 102, 51]], [[396, 441, 102, 52]], [[501, 443, 99, 51]], [[603, 444, 101, 51]]], [[[17, 490, 45, 157]], [[65, 491, 87, 50]], [[155, 492, 66, 50]], [[223, 493, 64, 50]], [[290, 493, 102, 51]], [[395, 495, 102, 51]], [[500, 496, 99, 51]], [[602, 497, 101, 51]]], [[], [[64, 544, 88, 50]], [[154, 545, 66, 50]], [[223, 546, 63, 50]], [[289, 547, 103, 50]], [[394, 548, 103, 51]], [[500, 549, 99, 51]], [[601, 550, 102, 51]]], [[], [[64, 597, 87, 51]], [[154, 598, 65, 50]], [[222, 599, 64, 50]], [[289, 600, 102, 50]], [[394, 601, 102, 51]], [[499, 602, 99, 51]], [[601, 604, 101, 50]]], [[[17, 650, 133, 51]], [], [[153, 651, 65, 50]], [[221, 652, 64, 50]], [[288, 653, 102, 51]], [[393, 654, 102, 51]], [[498, 655, 99, 51]], [[600, 657, 101, 50]]], [[[16, 703, 133, 51]], [], [], [[152, 704, 549, 57]], [], [], [], []]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#tess.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "\n",
    "# def recognize_structure(img):\n",
    "#     return finalboxes, img_bin\n",
    "\n",
    "img = cv2.imread('img/11.png')\n",
    "    #print(img.shape)\n",
    "    # 判断图像是否已经为灰度图像\n",
    "if len(img.shape) != 2:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_height, img_width = img.shape\n",
    "\n",
    "#print(\"img_height\", img_height, \"img_width\", img_width)\n",
    "\n",
    "# thresholding the image to a binary image\n",
    "# thresh, img_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "img_bin = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 5)\n",
    "\n",
    "# inverting the image\n",
    "img_bin = 255 - img_bin\n",
    "# Plotting the image to see the output\n",
    "\n",
    "# countcol(width) of kernel as 100th of total width\n",
    "# kernel_len = np.array(img).shape[1] // 100\n",
    "kernel_len_ver = img_height // 50\n",
    "kernel_len_hor = img_width // 50\n",
    "# Defining a vertical kernel to detect all vertical lines of image\n",
    "ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len_ver))  # shape (kernel_len, 1) inverted! xD\n",
    "#print(\"ver\", ver_kernel)\n",
    "#print(ver_kernel.shape)\n",
    "\n",
    "# Defining a horizontal kernel to detect all horizontal lines of image\n",
    "hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len_hor, 1))  # shape (1,kernel_ken) xD\n",
    "#print(\"hor\", hor_kernel)\n",
    "#print(hor_kernel.shape)\n",
    "\n",
    "# A kernel of 2x2\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "#print(kernel)\n",
    "#print(kernel.shape)\n",
    "\n",
    "# Use vertical kernel to detect and save the vertical lines in a jpg\n",
    "image_1 = cv2.erode(img_bin, ver_kernel, iterations=3)\n",
    "vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=4)\n",
    "# Plot the generated image\n",
    "\n",
    "# Use horizontal kernel to detect and save the horizontal lines in a jpg\n",
    "image_2 = cv2.erode(img_bin, hor_kernel, iterations=3)\n",
    "horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=4)\n",
    "\n",
    "# Combine horizontal and vertical lines in a new third image, with both having same weight.\n",
    "img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
    "\n",
    "# Eroding and thesholding the image\n",
    "img_vh = cv2.erode(~img_vh, kernel, iterations=2)\n",
    "\n",
    "thresh, img_vh = cv2.threshold(img_vh, 128, 255, cv2.THRESH_BINARY )\n",
    "#cv2.imwrite(\"/Users/marius/Desktop/img_vh.jpg\", img_vh)\n",
    "\n",
    "bitxor = cv2.bitwise_xor(img, img_vh)\n",
    "bitnot = cv2.bitwise_not(bitxor)\n",
    "# Plotting the generated image\n",
    "# cv2_imshow(bitnot)\n",
    "\n",
    "# Detect contours for following box detection\n",
    "contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#print(len(contours))\n",
    "#print(contours[0])\n",
    "#print(len(contours[0]))\n",
    "#print(cv2.boundingRect(contours[0]))\n",
    "\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b: b[1][i], reverse=reverse))\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "\n",
    "# Sort all the contours by top to bottom.\n",
    "contours, boundingBoxes = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "# Creating a list of heights for all detected boxes\n",
    "heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))]\n",
    "\n",
    "# Get mean of heights\n",
    "mean = np.mean(heights)\n",
    "\n",
    "# Create list box to store all boxes in\n",
    "box = []\n",
    "# Get position (x,y), width and height for every contour and show the contour on image\n",
    "#print(\"lencontours\", len(contours))\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    #print(\"x\", x, \"y\", y, \"w\", w, \"h\", h)\n",
    "    if (w < 0.9*img_width and h < 0.9*img_height):\n",
    "        image = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        box.append([x, y, w, h])\n",
    "\n",
    "# cv2_imshow(image)\n",
    "\n",
    "# Creating two lists to define row and column in which cell is located\n",
    "row = []\n",
    "column = []\n",
    "j = 0\n",
    "\n",
    "#print(\"len box\", len(box))\n",
    "# Sorting the boxes to their respective row and column\n",
    "for i in range(len(box)):\n",
    "    if (i == 0):\n",
    "        column.append(box[i])\n",
    "        previous = box[i]\n",
    "\n",
    "    else:\n",
    "        if (box[i][1] <= previous[1] + mean / 2):\n",
    "            column.append(box[i])\n",
    "            previous = box[i]\n",
    "\n",
    "            if (i == len(box) - 1):\n",
    "                row.append(column)\n",
    "\n",
    "        else:\n",
    "            row.append(column)\n",
    "            column = []\n",
    "            previous = box[i]\n",
    "            column.append(box[i])\n",
    "\n",
    "# print(column)\n",
    "# print(row)\n",
    "\n",
    "# calculating maximum number of cells\n",
    "countcol = 0\n",
    "index = 0\n",
    "for i in range(len(row)):\n",
    "    current = len(row[i])\n",
    "    #print(\"len\",len(row[i]))\n",
    "    if current > countcol:\n",
    "        countcol = current\n",
    "        index = i\n",
    "\n",
    "#print(\"countcol\", countcol)\n",
    "\n",
    "# Retrieving the center of each column\n",
    "#center = [int(row[i][j][0] + row[i][j][2] / 2) for j in range(len(row[i])) if row[0]]\n",
    "center = [int(row[index][j][0] + row[index][j][2] / 2) for j in range(len(row[index]))]\n",
    "#print(\"center\",center)\n",
    "\n",
    "center = np.array(center)\n",
    "center.sort()\n",
    "#print(\"center.sort()\", center)\n",
    "# Regarding the distance to the columns center, the boxes are arranged in respective order\n",
    "\n",
    "finalboxes = []\n",
    "for i in range(len(row)):\n",
    "    lis = []\n",
    "    for k in range(countcol):\n",
    "        lis.append([])\n",
    "    for j in range(len(row[i])):\n",
    "        diff = abs(center - (row[i][j][0] + row[i][j][2] / 4))\n",
    "        minimum = min(diff)\n",
    "        indexing = list(diff).index(minimum)\n",
    "        lis[indexing].append(row[i][j])\n",
    "    finalboxes.append(lis)\n",
    "        \n",
    "print(finalboxes)        \n",
    "print(img_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e75e688-ea7e-4a37-b46b-00ae7919b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "\n",
    "def output_to_xml(list_table_boxes, output_path):\n",
    "    root = etree.Element(\"table\")\n",
    "    for j in range(len(list_table_boxes)):\n",
    "        for k in range(len(list_table_boxes[0])):\n",
    "            if(list_table_boxes[j][k] != []):\n",
    "                cell = etree.SubElement(root, \"cell\")\n",
    "                cell.attrib[\"row\"] = str(j)\n",
    "                cell.attrib[\"column\"] = str(k)\n",
    "                bbox = etree.SubElement(cell, \"boundingbox\")\n",
    "                bbox.attrib[\"x\"] = str(list_table_boxes[j][k][0][0])\n",
    "                bbox.attrib[\"y\"] = str(list_table_boxes[j][k][0][1])\n",
    "                bbox.attrib[\"w\"] = str(list_table_boxes[j][k][0][2])\n",
    "                bbox.attrib[\"h\"] = str(list_table_boxes[j][k][0][3])\n",
    "\n",
    "    et = etree.ElementTree(root)\n",
    "    et.write(output_path + \"xml\", pretty_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb868ba-e294-4df5-a887-220b383c3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_to_xml(finalboxes, 'xml/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5cd75ed-cadb-4a47-8830-3c26984aec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452/1403133530.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  s=np.array(finalboxes).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=np.array(finalboxes).shape\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d3fa99f-e036-4c5b-af01-fa68d09960be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "def get_row_column(list_table_boxes):\n",
    "    x=len(list_table_boxes)\n",
    "    y=len(list_table_boxes[0])\n",
    "    #print(x,y)\n",
    "    #dp = [[0] * (3) for _ in range(3)]\n",
    "    arr = [[0] * (y)for _ in range(x)] \n",
    "    #print(arr)\n",
    "    for j in range(x):\n",
    "        for k in range(y):\n",
    "            #print(list_table_boxes[j][k])\n",
    "            if(list_table_boxes[j][k] != []):\n",
    "                #print(j,k)\n",
    "                arr[j][k]=1\n",
    "                #print(arr)\n",
    "\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16e730a-fc3b-47cb-ae17-efc295e5050b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 1, 0, 0, 1, 1, 1],\n",
       " [1, 0, 1, 1, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1, 1, 1, 1],\n",
       " [1, 0, 1, 1, 0, 1, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 0, 1, 1, 1, 1, 1, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc=get_row_column(finalboxes)\n",
    "rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a0d2569-d23d-477c-9d8f-74ec33134169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heng(m, n):\n",
    "    i = 1\n",
    "    while True:\n",
    "        if (n+i)>7 :\n",
    "            break;\n",
    "        if a[m][n+i] == 0:\n",
    "            b[m][n+i] = 1\n",
    "            i += 1  #向右搜第几列———n\n",
    "        if (n+i)>7 :\n",
    "            break;\n",
    "        if a[m][n+i] == 1 :\n",
    "            break\n",
    "    \n",
    "    hash_table[m,n]=[m, n+i-1]\n",
    "    return(hash_table[m,n])\n",
    "\n",
    "\n",
    "def zong(m, n):\n",
    "   \n",
    "    j = 1\n",
    "    while True:\n",
    "        if (m+j)>13:\n",
    "            break;\n",
    "\n",
    "        if b[m+j][n] == 0:\n",
    "            #b[m+j][n] = 1\n",
    "            j += 1  #向下搜第几行———m\n",
    "        if (m+j)>13:\n",
    "            break;\n",
    "        if b[m+j][n] == 1:\n",
    "            break\n",
    "    print(m,n)        \n",
    "    x,y=hash_table[m,n]\n",
    "    hash_table[m,n]=[m+j-1, y]\n",
    "    return(hash_table[m,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36ffcec0-688e-46c5-a9d1-5e0a9db0c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 2\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "1 0\n",
      "1 2\n",
      "1 3\n",
      "1 5\n",
      "1 7\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "3 0\n",
      "3 2\n",
      "3 3\n",
      "3 5\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "8 5\n",
      "8 6\n",
      "8 7\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "9 5\n",
      "9 6\n",
      "9 7\n",
      "10 1\n",
      "10 2\n",
      "10 3\n",
      "10 4\n",
      "10 5\n",
      "10 6\n",
      "10 7\n",
      "11 1\n",
      "11 2\n",
      "11 3\n",
      "11 4\n",
      "11 5\n",
      "11 6\n",
      "11 7\n",
      "12 0\n",
      "12 2\n",
      "12 3\n",
      "12 4\n",
      "12 5\n",
      "12 6\n",
      "12 7\n",
      "13 0\n",
      "13 3\n",
      "0 0\n",
      "0 2\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "1 0\n",
      "1 2\n",
      "1 3\n",
      "1 5\n",
      "1 7\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "3 0\n",
      "3 2\n",
      "3 3\n",
      "3 5\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "8 5\n",
      "8 6\n",
      "8 7\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "9 5\n",
      "9 6\n",
      "9 7\n",
      "10 1\n",
      "10 2\n",
      "10 3\n",
      "10 4\n",
      "10 5\n",
      "10 6\n",
      "10 7\n",
      "11 1\n",
      "11 2\n",
      "11 3\n",
      "11 4\n",
      "11 5\n",
      "11 6\n",
      "11 7\n",
      "12 0\n",
      "12 2\n",
      "12 3\n",
      "12 4\n",
      "12 5\n",
      "12 6\n",
      "12 7\n",
      "13 0\n",
      "13 3\n"
     ]
    }
   ],
   "source": [
    "a=rc\n",
    "b=get_row_column(finalboxes)\n",
    "\n",
    "hash_table={}\n",
    "for i in range(len(a)):\n",
    "    for j in range(len(a[i])):\n",
    "        if a[i][j]==1:\n",
    "            print(i,j)\n",
    "            c=heng(i,j)\n",
    "\n",
    "#             print(c)\n",
    "#             print(\"***********************************\")\n",
    "            \n",
    "\n",
    "for i in range(len(b)):\n",
    "    for j in range(len(b[i])):\n",
    "        if a[i][j]==1:\n",
    "\n",
    "            c=zong(i,j)\n",
    "\n",
    "#             print(c)\n",
    "#             print(\"***********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38e3afeb-18e4-40a7-b3a1-d38a1c98a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) [0, 1]\n",
      "(0, 2) [0, 4]\n",
      "(0, 5) [0, 5]\n",
      "(0, 6) [0, 6]\n",
      "(0, 7) [0, 7]\n",
      "(1, 0) [2, 1]\n",
      "(1, 2) [2, 2]\n",
      "(1, 3) [2, 4]\n",
      "(1, 5) [1, 6]\n",
      "(1, 7) [1, 7]\n",
      "(2, 4) [2, 4]\n",
      "(2, 5) [2, 5]\n",
      "(2, 6) [2, 6]\n",
      "(2, 7) [2, 7]\n",
      "(3, 0) [3, 1]\n",
      "(3, 2) [3, 2]\n",
      "(3, 3) [3, 4]\n",
      "(3, 5) [3, 7]\n",
      "(4, 0) [6, 0]\n",
      "(4, 1) [4, 1]\n",
      "(4, 2) [4, 2]\n",
      "(4, 3) [4, 3]\n",
      "(4, 4) [4, 4]\n",
      "(4, 5) [4, 5]\n",
      "(4, 6) [4, 6]\n",
      "(4, 7) [4, 7]\n",
      "(5, 1) [5, 1]\n",
      "(5, 2) [5, 2]\n",
      "(5, 3) [5, 3]\n",
      "(5, 4) [5, 4]\n",
      "(5, 5) [5, 5]\n",
      "(5, 6) [5, 6]\n",
      "(5, 7) [5, 7]\n",
      "(6, 1) [6, 1]\n",
      "(6, 2) [6, 2]\n",
      "(6, 3) [6, 3]\n",
      "(6, 4) [6, 4]\n",
      "(6, 5) [6, 5]\n",
      "(6, 6) [6, 6]\n",
      "(6, 7) [6, 7]\n",
      "(7, 0) [8, 0]\n",
      "(7, 1) [7, 1]\n",
      "(7, 2) [7, 2]\n",
      "(7, 3) [7, 3]\n",
      "(7, 4) [7, 4]\n",
      "(7, 5) [7, 5]\n",
      "(7, 6) [7, 6]\n",
      "(7, 7) [7, 7]\n",
      "(8, 1) [8, 1]\n",
      "(8, 2) [8, 2]\n",
      "(8, 3) [8, 3]\n",
      "(8, 4) [8, 4]\n",
      "(8, 5) [8, 5]\n",
      "(8, 6) [8, 6]\n",
      "(8, 7) [8, 7]\n",
      "(9, 0) [11, 0]\n",
      "(9, 1) [9, 1]\n",
      "(9, 2) [9, 2]\n",
      "(9, 3) [9, 3]\n",
      "(9, 4) [9, 4]\n",
      "(9, 5) [9, 5]\n",
      "(9, 6) [9, 6]\n",
      "(9, 7) [9, 7]\n",
      "(10, 1) [10, 1]\n",
      "(10, 2) [10, 2]\n",
      "(10, 3) [10, 3]\n",
      "(10, 4) [10, 4]\n",
      "(10, 5) [10, 5]\n",
      "(10, 6) [10, 6]\n",
      "(10, 7) [10, 7]\n",
      "(11, 1) [11, 1]\n",
      "(11, 2) [11, 2]\n",
      "(11, 3) [11, 3]\n",
      "(11, 4) [11, 4]\n",
      "(11, 5) [11, 5]\n",
      "(11, 6) [11, 6]\n",
      "(11, 7) [11, 7]\n",
      "(12, 0) [12, 1]\n",
      "(12, 2) [12, 2]\n",
      "(12, 3) [12, 3]\n",
      "(12, 4) [12, 4]\n",
      "(12, 5) [12, 5]\n",
      "(12, 6) [12, 6]\n",
      "(12, 7) [12, 7]\n",
      "(13, 0) [13, 2]\n",
      "(13, 3) [13, 7]\n"
     ]
    }
   ],
   "source": [
    "# 遍历字典\n",
    "for key, value in hash_table.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cce99d9-8a80-4ef6-b353-931600d30447",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Attempt to overwrite cell: sheetname='Sheet1' rowx=2 colx=4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     row1,column1 \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m     13\u001b[0m     row2,column2 \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 14\u001b[0m     \u001b[43msheet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhaha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 保存表格\u001b[39;00m\n\u001b[1;32m     17\u001b[0m work_book\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout3.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xlwt/Worksheet.py:1114\u001b[0m, in \u001b[0;36mWorksheet.write_merge\u001b[0;34m(self, r1, r2, c1, c2, label, style)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m c1 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m c2 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r1 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r2 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m65535\u001b[39m\n\u001b[0;32m-> 1114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c2 \u001b[38;5;241m>\u001b[39m c1:\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow(r1)\u001b[38;5;241m.\u001b[39mwrite_blanks(c1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, c2,  style) \u001b[38;5;66;03m# skip (r1, c1)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xlwt/Worksheet.py:1088\u001b[0m, in \u001b[0;36mWorksheet.write\u001b[0;34m(self, r, c, label, style)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, c, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, style\u001b[38;5;241m=\u001b[39mStyle\u001b[38;5;241m.\u001b[39mdefault_style):\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m    This method is used to write a cell to a :class:`Worksheet`.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m       :class:`~xlwt.Style.XFStyle` object.\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xlwt/Row.py:234\u001b[0m, in \u001b[0;36mRow.write\u001b[0;34m(self, col, label, style)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(label, basestring):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(label) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mStrCell\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__parent_wb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_cell(col, BlankCell(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idx, col, style_index))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xlwt/Row.py:154\u001b[0m, in \u001b[0;36mRow.insert_cell\u001b[0;34m(self, col_index, cell_obj)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__parent\u001b[38;5;241m.\u001b[39m_cell_overwrite_ok:\n\u001b[1;32m    152\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt to overwrite cell: sheetname=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m rowx=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m colx=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__parent\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idx, col_index)\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg)\n\u001b[1;32m    155\u001b[0m prev_cell_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__cells[col_index]\n\u001b[1;32m    156\u001b[0m sst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(prev_cell_obj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msst_idx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mException\u001b[0m: Attempt to overwrite cell: sheetname='Sheet1' rowx=2 colx=4"
     ]
    }
   ],
   "source": [
    "import xlwt\n",
    " \n",
    "# 创建工作簿对象\n",
    "work_book = xlwt.Workbook('/Users/jzq/Desktop/服务外包/qzj666-main/scripts/output.xlsx')\n",
    " \n",
    "# 创建工作表对象\n",
    "sheet = work_book.add_sheet(\"Sheet1\")\n",
    " \n",
    "# 往表中写入内容\n",
    "# write_merge(a,b,c,d,message)函数将从第a行到第b行的第c列到第d列的单元格合并，并填入内容message\n",
    "for key, value in hash_table.items():\n",
    "    row1,column1 = key\n",
    "    row2,column2 = value\n",
    "    sheet.write_merge(row1, row2, column1, column2, 'haha')\n",
    " \n",
    "# 保存表格\n",
    "work_book.save('out3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e9484-7c4b-490d-92f9-6ae967725df3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Workbook' object has no attribute 'add_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m ws \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39msheets[sheet_name]\n\u001b[1;32m     17\u001b[0m wb \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39mbook\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mwb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_format\u001b[49m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m:Ture,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malign\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m}]  \u001b[38;5;66;03m#设置格式\u001b[39;00m\n\u001b[1;32m     19\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m表格标题\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m ws\u001b[38;5;241m.\u001b[39mmerge_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1:H1\u001b[39m\u001b[38;5;124m'\u001b[39m,data,cell_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m)        \u001b[38;5;66;03m#合并单元格设置单元格样式\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Workbook' object has no attribute 'add_format'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    " \n",
    "#dir_name =/test/                #需存放的路径\n",
    " \n",
    "#需注意每次生成excle时,对已经存在的同名文件会直接进行覆盖\n",
    "#我后续的文件是程序中支持下载的,所以需要每次是一份新的\n",
    "#需要的路径和文件名，未传路径的话会直接存在当前项目目录下\n",
    "writer = pd.ExcelWriter('output.xlsx')    \n",
    "pd_list = []        #待处理数据\n",
    "pd_columns = []        #表格标题行\n",
    "sheet_name = 'test'    \n",
    "pd_excle = pd.DataFrame(pd_list,columns=pd_columns)   \n",
    " \n",
    "#float_format科学计数法,index默认为Ture会在最左侧生成一列索引列，不需要的话False即可，header默认为0，从excle文件的第几行存入当前数据表，我传的1，因为后续要对表格加标题\n",
    "pd_excle.to_excel(writer,sheet_name,float_format='%.5f',index=False,header=1)\n",
    "ws = writer.sheets[sheet_name]\n",
    "wb = writer.book\n",
    "format = wb.add_format({'bold':Ture,'align':'center'})    #设置格式\n",
    "data = '表格标题'\n",
    "ws.merge_range('A1:H1',data,cell_format=format)        #合并单元格设置单元格样式\n",
    "writer.save('out.xlsx')\n",
    "#获取文件路径\n",
    "path = writer.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef329810-e2b9-428d-b4e3-7bd58955a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Collecting xlwt\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/44/48/def306413b25c3d01753603b1a222a011b8621aed27cd7f89cbc27e6b0f4/xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlwt\n",
      "Successfully installed xlwt-1.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df16a385-c2a1-4484-9a25-8c5350c8f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并单元格: [(3, 5, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# 解析XML文件\n",
    "tree = ET.parse('xml/11.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# 存储单元格位置和尺寸的字典\n",
    "cell_dict = {}\n",
    "\n",
    "# 遍历每个单元格\n",
    "for cell in root.findall('.//cell'):\n",
    "    row = int(cell.get('row'))\n",
    "    column = int(cell.get('column'))\n",
    "    bbox = cell.find('boundingbox')\n",
    "    x = int(bbox.get('x'))\n",
    "    y = int(bbox.get('y'))\n",
    "    w = int(bbox.get('w'))\n",
    "    h = int(bbox.get('h'))\n",
    "    cell_dict[(row, column)] = (x, y, w, h)\n",
    "\n",
    "# 存储合并单元格的列表\n",
    "merged_cells = []\n",
    "\n",
    "# 检查每个单元格的相邻单元格是否相交\n",
    "for (row, column), (x, y, w, h) in cell_dict.items():\n",
    "    # 检查右侧相邻单元格\n",
    "    if (row, column+1) in cell_dict:\n",
    "        (x2, y2, w2, h2) = cell_dict[(row, column+1)]\n",
    "        if x+w > x2 and y < y2+h2 and y+h > y2:\n",
    "            merged_cells.append((row, column, row, column+1))\n",
    "    # 检查下方相邻单元格\n",
    "    if (row+1, column) in cell_dict:\n",
    "        (x2, y2, w2, h2) = cell_dict[(row+1, column)]\n",
    "        if y+h > y2 and x < x2+w2 and x+w > x2:\n",
    "            merged_cells.append((row, column, row+1, column))\n",
    "\n",
    "print(\"合并单元格:\", merged_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbcd9bf-a7a6-4256-8f84-12e2a7ed6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 26, 12, 134, 51), (0, 2, 163, 14, 236, 52), (0, 5, 402, 17, 102, 50), (0, 6, 507, 18, 203, 52), (0, 7, 713, 20, 7, 50), (1, 0, 25, 65, 134, 105), (1, 2, 161, 67, 66, 103), (1, 3, 229, 67, 65, 104), (1, 5, 297, 68, 412, 55), (1, 7, 712, 73, 8, 50), (2, 4, 296, 121, 102, 51), (2, 5, 401, 123, 102, 51), (2, 6, 506, 124, 98, 51), (2, 7, 607, 125, 101, 51), (3, 0, 24, 172, 133, 51), (3, 2, 160, 173, 66, 51), (3, 3, 228, 174, 64, 50), (3, 5, 295, 175, 413, 55), (4, 0, 21, 225, 45, 156), (4, 1, 69, 225, 87, 51), (4, 2, 159, 226, 66, 51), (4, 3, 228, 227, 63, 50), (4, 4, 294, 228, 102, 51), (4, 5, 399, 229, 102, 51), (4, 6, 504, 231, 99, 50), (4, 7, 606, 232, 101, 51), (5, 1, 68, 278, 88, 51), (5, 2, 158, 279, 66, 51), (5, 3, 227, 280, 63, 51), (5, 4, 293, 281, 102, 51), (5, 5, 398, 282, 102, 51), (5, 6, 503, 284, 99, 51), (5, 7, 605, 285, 101, 51), (6, 1, 67, 332, 88, 50), (6, 2, 158, 332, 65, 51), (6, 3, 226, 333, 64, 51), (6, 4, 292, 334, 103, 51), (6, 5, 397, 335, 103, 51), (6, 6, 503, 337, 98, 51), (6, 7, 604, 338, 101, 51), (7, 0, 20, 384, 44, 103), (7, 1, 66, 385, 88, 50), (7, 2, 157, 386, 65, 50), (7, 3, 225, 386, 64, 51), (7, 4, 292, 387, 102, 51), (7, 5, 397, 388, 102, 51), (7, 6, 502, 390, 99, 51), (7, 7, 603, 391, 102, 51), (8, 1, 66, 438, 87, 50), (8, 2, 156, 439, 65, 50), (8, 3, 224, 439, 64, 51), (8, 4, 291, 440, 102, 51), (8, 5, 396, 441, 102, 52), (8, 6, 501, 443, 99, 51), (8, 7, 603, 444, 101, 51), (9, 0, 17, 490, 45, 157), (9, 1, 65, 491, 87, 50), (9, 2, 155, 492, 66, 50), (9, 3, 223, 493, 64, 50), (9, 4, 290, 493, 102, 51), (9, 5, 395, 495, 102, 51), (9, 6, 500, 496, 99, 51), (9, 7, 602, 497, 101, 51), (10, 1, 64, 544, 88, 50), (10, 2, 154, 545, 66, 50), (10, 3, 223, 546, 63, 50), (10, 4, 289, 547, 103, 50), (10, 5, 394, 548, 103, 51), (10, 6, 500, 549, 99, 51), (10, 7, 601, 550, 102, 51), (11, 1, 64, 597, 87, 51), (11, 2, 154, 598, 65, 50), (11, 3, 222, 599, 64, 50), (11, 4, 289, 600, 102, 50), (11, 5, 394, 601, 102, 51), (11, 6, 499, 602, 99, 51), (11, 7, 601, 604, 101, 50), (12, 0, 17, 650, 133, 51), (12, 2, 153, 651, 65, 50), (12, 3, 221, 652, 64, 50), (12, 4, 288, 653, 102, 51), (12, 5, 393, 654, 102, 51), (12, 6, 498, 655, 99, 51), (12, 7, 600, 657, 101, 50), (13, 0, 16, 703, 133, 51), (13, 3, 152, 704, 549, 57)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# 解析XML文件\n",
    "tree = ET.parse('xml/11.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# 提取每个单元格的行、列坐标以及宽度、高度等信息\n",
    "cell_info = []\n",
    "for cell in root.findall('cell'):\n",
    "    row = int(cell.get('row'))\n",
    "    column = int(cell.get('column'))\n",
    "    boundingbox = cell.find('boundingbox')\n",
    "    x = int(boundingbox.get('x'))\n",
    "    y = int(boundingbox.get('y'))\n",
    "    w = int(boundingbox.get('w'))\n",
    "    h = int(boundingbox.get('h'))\n",
    "    cell_info.append((row, column, x, y, w, h))\n",
    "    \n",
    "print(cell_info)\n",
    "    \n",
    "\n",
    "# 检查每个单元格是否为合并单元格\n",
    "merged_cells = []\n",
    "for i in range(len(cell_info)):\n",
    "    row, column, x, y, w, h = cell_info[i]\n",
    "    for j in range(i+1, len(cell_info)):\n",
    "        next_row, next_column, next_x, next_y, next_w, next_h = cell_info[j]\n",
    "        if next_row == row and next_column == column+1 and next_x == x+w and next_h == h:\n",
    "            merged_cells.append((row, column, row, column+1))\n",
    "        elif next_row == row+1 and next_column == column and next_y == y+h and next_w == w:\n",
    "            merged_cells.append((row, column, row+1, column))\n",
    "\n",
    "print(merged_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7710853-8d08-42fb-8e6a-7785198ee744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
